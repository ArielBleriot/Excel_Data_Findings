🌩️ AWS Serverless ETL Pipeline

This project demonstrates how to build a scalable, serverless ETL pipeline on AWS to process and analyze weather data efficiently.

🏗️ Architecture Overview

AWS S3 – Stores incoming raw JSON files and processed Parquet files
AWS Lambda – Triggered on new file uploads, flattens JSON using pandas, writes Parquet back to S3
AWS Glue – Catalogs processed data for querying
Amazon Athena – Enables SQL-based analytics on S3-stored data

💻 Tech Stack

Python: pandas, boto3, pyarrow

AWS Services: S3, Lambda, Glue, Athena

Tools: DBeaver (database visualization & monitoring)

⚡ Key Features

Converts JSON → Parquet for optimized storage and fast querying

Fully automated pipeline triggered on file upload

Designed with scalability and cost-efficiency in mind

🛠️ What I Learned

Event-driven data processing using AWS Lambda

Schema evolution and data partitioning best practices

Handling Lambda packaging issues with dependencies

⚠️ Challenges Faced

URL decoding of S3 object keys from event payload

Configuring IAM policies for secure Lambda execution

Managing Lambda execution time and memory for large datasets

📌 Key Takeaways

This project reinforced my skills in:

Serverless architectures

AWS data services

Automated ETL pipelines

A foundational experience for real-world Data Engineering projects.

📂 Repository Links

Explore this project on GitHub: Airflow1_project ETL

Related project: Customer Churn Prediction

Made with ❤️ by Ariel Bleriot Ndonfak Sapi
